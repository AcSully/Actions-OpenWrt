{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO11 Tutorial",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/models/ultralytics/yolo11\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "\n",
        "Welcome to the Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLO11 and understand its features and capabilities.\n",
        "\n",
        "YOLO11 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "  <a href=\"https://www.youtube.com/watch?v=ZN3nRZT7b24\" target=\"_blank\">\n",
        "    <img src=\"https://img.youtube.com/vi/ZN3nRZT7b24/maxresdefault.jpg\" alt=\"Ultralytics Video\" width=\"720\" style=\"border-radius: 10px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\"></a>\n",
        "  \n",
        "  <p style=\"font-size: 16px; font-family: Arial, sans-serif; color: #555;\">\n",
        "    <strong>Watch: </strong> How to Train\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics\">Ultralytics</a>\n",
        "  <a href=\"https://docs.ultralytics.com/models/yolo11/\">YOLO11</a> Model on Custom Dataset using Google Colab Notebook üöÄ</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59e04ae-5351-4375-c957-ce0ee8eca115"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 33.0/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f5144d-9023-46ce-8ae5-97c3c4c8db19"
      },
      "source": [
        "# Run inference on an image with YOLO11n\n",
        "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 93.5MB/s]\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
            "100% 49.2k/49.2k [00:00<00:00, 6.36MB/s]\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 66.0ms\n",
            "Speed: 12.9ms preprocess, 66.0ms inference, 414.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Val\n",
        "Validate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLO11 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLO11 Val Docs](https://docs.ultralytics.com/modes/val/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1f0eb7-3f7a-432e-c0b4-78aaa38ff24f"
      },
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 780M/780M [00:08<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "outputId": "568effb7-81c0-49aa-a5cd-770f5458df2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Validate YOLO11n on COCO8 val\n",
        "!yolo val model=yolo11n.pt data=coco8.yaml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "Dataset 'coco8.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n",
            "100% 433k/433k [00:00<00:00, 10.5MB/s]\n",
            "Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% 25/25 [00:00<00:00, 4296.21file/s]\n",
            "Dataset download success ‚úÖ (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 20.3MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 116.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.55s/it]\n",
            "                   all          4         17       0.57       0.85      0.847      0.632\n",
            "                person          3         10      0.557        0.6      0.585      0.272\n",
            "                   dog          1          1      0.548          1      0.995      0.697\n",
            "                 horse          1          2      0.531          1      0.995      0.674\n",
            "              elephant          1          2      0.371        0.5      0.516      0.256\n",
            "              umbrella          1          1      0.569          1      0.995      0.995\n",
            "          potted plant          1          1      0.847          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 19.9ms inference, 0.0ms loss, 35.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://ultralytics.com/hub\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLO11 üöÄ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ."
      ],
      "metadata": {
        "id": "ktegpM42AooT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab751112-e369-4a3c-fd91-c57874a25f3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/713.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.7/713.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m713.5/713.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m979.7/979.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "outputId": "6f44c138-e924-4e29-92e9-b62e661b9769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train YOLO11n on COCO8 for 3 epochs\n",
        "!yolo train model=yolo11n.pt data=coco8.yaml epochs=3 imgsz=640"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738893661.304903    2180 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738893661.381132    2180 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLO11n summary: 319 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/acsully/general/73758d42127e4df5be68650a81f88591\u001b[0m\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 44150.57it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/3      0.74G     0.9753      2.326      1.291         18        640: 100% 1/1 [00:01<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.81it/s]\n",
            "                   all          4         17      0.586       0.85      0.878      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/3     0.713G      1.299      3.249      1.677         22        640: 100% 1/1 [00:00<00:00,  6.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.67it/s]\n",
            "                   all          4         17      0.592       0.85      0.848       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/3     0.705G      1.354      2.837      1.479         27        640: 100% 1/1 [00:00<00:00,  6.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.77it/s]\n",
            "                   all          4         17      0.575       0.85       0.85      0.649\n",
            "\n",
            "3 epochs completed in 0.002 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 10.41it/s]\n",
            "                   all          4         17      0.575       0.85       0.85      0.632\n",
            "                person          3         10      0.573        0.6      0.594      0.274\n",
            "                   dog          1          1      0.548          1      0.995      0.796\n",
            "                 horse          1          2      0.556          1      0.995      0.674\n",
            "              elephant          1          2      0.361        0.5      0.524      0.259\n",
            "              umbrella          1          1      0.567          1      0.995      0.895\n",
            "          potted plant          1          1      0.848          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 6.7ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : shiny_earthworm_5733\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : \u001b[38;5;39mhttps://www.comet.com/acsully/general/73758d42127e4df5be68650a81f88591\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84824, 0.87795)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.63027, 0.64906)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57478, 0.5919)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 39.672\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.97532, 1.35397)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.3256, 3.24852)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.29133, 1.67658)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65088, 1.67785)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.01442, 1.02784)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37625, 1.38707)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 2 (14.91 KB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 file(s), remaining 3.71 MB/8.82 MB\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ‚úÖ        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `dynamic`, `int8`, `batch`, `data`                  |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch`, `data` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`, `data`                             |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | ‚úÖ        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | ‚úÖ        | `imgsz`, `int8`, `data`                                              |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | ‚úÖ        | `imgsz`, `batch`, `name`                                             |"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolo11n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIjW4igCjqD",
        "outputId": "3d7d1a0b-5789-4f49-877a-6313eb8ab487"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1+cu124...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 2.8s, saved as 'yolo11n.torchscript' (10.5 MB)\n",
            "\n",
            "Export complete (4.5s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.torchscript imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Python Usage\n",
        "\n",
        "YOLO11 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLO11 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLO11 Python Docs](https://docs.ultralytics.com/usage/python/)."
      ],
      "metadata": {
        "id": "kUMOQ0OeDBJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolo11n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e40557c-45e8-4930-fd9f-4c1f14b1f030"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLO11n summary: 319 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/acsully/general/f5277ebba518448ea76db9d346c428ac\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      0.74G     0.9753      2.326      1.291         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.586       0.85      0.878      0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.713G      1.299      3.249      1.677         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.592       0.85      0.848       0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.705G      1.354      2.837      1.479         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.575       0.85       0.85      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.003 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 21.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.575       0.85       0.85      0.632\n",
            "                person          3         10      0.573        0.6      0.594      0.274\n",
            "                   dog          1          1      0.548          1      0.995      0.796\n",
            "                 horse          1          2      0.556          1      0.995      0.674\n",
            "              elephant          1          2      0.361        0.5      0.524      0.259\n",
            "              umbrella          1          1      0.567          1      0.995      0.895\n",
            "          potted plant          1          1      0.848          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 4.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : defensive_patio_5161\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/acsully/general/f5277ebba518448ea76db9d346c428ac\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84824, 0.87795)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.63027, 0.64906)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57478, 0.5919)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 34.145\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.97532, 1.35397)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.3256, 3.24852)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.29133, 1.67658)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65088, 1.67785)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.01442, 1.02784)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37625, 1.38707)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url                 : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fultralytics%2Fultralytics%2Fblob%2Fmain%2Fexamples%2Ftutorial.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.574       0.85       0.85      0.653\n",
            "                person          3         10      0.571        0.6      0.594      0.295\n",
            "                   dog          1          1      0.546          1      0.995      0.796\n",
            "                 horse          1          2      0.552          1      0.995      0.674\n",
            "              elephant          1          2      0.359        0.5      0.525       0.26\n",
            "              umbrella          1          1      0.566          1      0.995      0.995\n",
            "          potted plant          1          1      0.847          1      0.995      0.895\n",
            "Speed: 1.7ms preprocess, 42.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134k/134k [00:00<00:00, 7.71MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 47.7ms\n",
            "Speed: 5.8ms preprocess, 47.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.3 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxslim\n",
            "  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim) (24.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.1.24)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16.0/16.0 MB 124.7 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 142.9/142.9 kB 308.8 MB/s eta 0:00:00\n",
            "Downloading onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 291.5/291.5 MB 231.5 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 kB 200.3 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 kB 231.0 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx, humanfriendly, onnxslim, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-gpu-1.20.1 onnxslim-0.1.48\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 21.6s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim', 'onnxruntime-gpu']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 23.1s, saved as 'runs/detect/train2/weights/best.onnx' (10.2 MB)\n",
            "\n",
            "Export complete (24.6s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train2/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train2/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train2/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tasks\n",
        "\n",
        "YOLO11 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLO11 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n",
        "\n",
        "<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n"
      ],
      "metadata": {
        "id": "Phm9ccmOKye5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLO11 _detection_ models have no suffix and are the default YOLO11 models, i.e. `yolo11n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n.pt')  # load a pretrained YOLO detection model\n",
        "model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab33cc21-5ee9-41db-9dc2-721581f75e75"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLO11n summary: 319 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/acsully/general/6c8321a771674cc384d7257232282ef5\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.732G     0.9753      2.326      1.291         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.586       0.85      0.878      0.634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.713G      1.299      3.249      1.677         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.592       0.85      0.848       0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.713G      1.354      2.837      1.479         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.575       0.85       0.85      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.003 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.575       0.85       0.85      0.632\n",
            "                person          3         10      0.573        0.6      0.594      0.274\n",
            "                   dog          1          1      0.548          1      0.995      0.796\n",
            "                 horse          1          2      0.556          1      0.995      0.674\n",
            "              elephant          1          2      0.361        0.5      0.524      0.259\n",
            "              umbrella          1          1      0.567          1      0.995      0.895\n",
            "          potted plant          1          1      0.848          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 5.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : real_canity_9935\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/acsully/general/6c8321a771674cc384d7257232282ef5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.84824, 0.87795)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.63027, 0.64906)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.57478, 0.5919)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 0.85\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.614\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2624080\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 12.027\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.97532, 1.35397)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.3256, 3.24852)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.29133, 1.67658)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.65088, 1.67785)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.01442, 1.02784)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.37625, 1.38707)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url                 : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fultralytics%2Fultralytics%2Fblob%2Fmain%2Fexamples%2Ftutorial.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/detect/train3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.28 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 24.6ms\n",
            "Speed: 8.1ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/train32'\n",
              " speed: {'preprocess': 8.136510848999023, 'inference': 24.626731872558594, 'postprocess': 2.198934555053711}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLO11 _segmentation_ models use the `-seg` suffix, i.e. `yolo11n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-seg.pt')  # load a pretrained YOLO segmentation model\n",
        "model.train(data='coco8-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa994472-99ca-46c5-e8fb-795da9980ef0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.90M/5.90M [00:00<00:00, 121MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=coco8-seg.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset 'coco8-seg.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8-seg/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8-seg.zip to '/content/datasets/coco8-seg.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 439k/439k [00:00<00:00, 14.1MB/s]\n",
            "Unzipping /content/datasets/coco8-seg.zip to /content/datasets/coco8-seg...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 3501.79file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.7s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    717680  ultralytics.nn.modules.head.Segment          [80, 32, 64, [64, 128, 256]]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO11n-seg summary: 355 layers, 2,876,848 parameters, 2,876,832 gradients, 10.5 GFLOPs\n",
            "\n",
            "Transferred 561/561 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/acsully/general/d1d53bb54e2148309331465ebb487c21\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8-seg/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2880.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8-seg/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-seg/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 554.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8-seg/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         1G      1.096       2.13      2.753      1.367         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.799       0.89      0.939      0.666      0.742      0.833      0.821      0.567\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3      0.95G      1.088      3.382      2.965      1.438         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.784      0.896      0.939      0.663      0.725      0.838      0.822      0.565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.931G       1.09      2.869      2.837      1.278         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.782      0.897      0.939       0.67      0.723      0.838      0.821      0.565\n",
            "\n",
            "3 epochs completed in 0.003 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.1MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.1MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,868,664 parameters, 0 gradients, 10.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 15.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.783      0.895      0.938      0.671      0.724      0.837      0.821      0.564\n",
            "                person          3         10      0.721       0.52      0.655      0.319      0.721       0.52      0.614      0.246\n",
            "                   dog          1          1      0.744          1      0.995      0.895      0.744          1      0.995      0.895\n",
            "                 horse          1          2       0.63          1      0.995      0.581       0.63          1      0.828        0.2\n",
            "              elephant          1          2          1      0.851      0.995      0.341      0.649        0.5        0.5       0.25\n",
            "              umbrella          1          1      0.672          1      0.995      0.995      0.672          1      0.995      0.895\n",
            "          potted plant          1          1      0.928          1      0.995      0.895      0.928          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 5.8ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : elaborate_kiwifruit_9274\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/acsully/general/d1d53bb54e2148309331465ebb487c21\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 8.092e-07)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.9383028998875536, 0.93897)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(M) [8]     : (0.82118, 0.82154)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.6631, 0.6712100285924893)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(M) [8]  : (0.5636612404684096, 0.56661)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.78213, 0.7987)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(M) [8] : (0.72304, 0.74178)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.89026, 0.89713)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(M) [8]    : (0.83333, 0.83805)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 10.529\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2876848\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 18.996\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (1.08848, 1.09631)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (2.75259, 2.96525)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.27846, 1.43753)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/seg_loss [6]       : (2.12966, 3.38167)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (1.52323, 1.53338)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (1.00341, 1.01465)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.32617, 1.33166)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/seg_loss [6]         : (2.51529, 2.52579)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url                 : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fultralytics%2Fultralytics%2Fblob%2Fmain%2Fexamples%2Ftutorial.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8-seg.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-seg.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/segment/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : segment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 17\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.79 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 76.3ms\n",
            "Speed: 5.0ms preprocess, 76.3ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/segment/train2'\n",
              " speed: {'preprocess': 5.000591278076172, 'inference': 76.31993293762207, 'postprocess': 7.844209671020508}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLO11 _classification_ models use the `-cls` suffix, i.e. `yolo11n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
      ],
      "metadata": {
        "id": "ax3p94VNK9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-cls.pt')  # load a pretrained YOLO classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "5q9Zu6zlL5rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cff6ae-80a4-4ca3-b424-f9a82029cfa4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.52M/5.52M [00:00<00:00, 97.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=mnist160, epochs=3, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset not found ‚ö†Ô∏è, missing path /content/datasets/mnist160, attempting download...\n",
            "Downloading https://ultralytics.com/assets/mnist160.zip to '/content/datasets/mnist160.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70.0k/70.0k [00:00<00:00, 6.58MB/s]\n",
            "Unzipping /content/datasets/mnist160.zip to /content/datasets/mnist160...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184/184 [00:00<00:00, 10834.19file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.7s), saved to \u001b[1m/content/datasets/mnist160\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist160/train... found 80 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist160/test... found 80 images in 10 classes ‚úÖ \n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
            "YOLO11n-cls summary: 151 layers, 1,543,914 parameters, 1,543,914 gradients, 3.3 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/acsully/general/4f0de2e2fc1444db80defab800d1771d\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/mnist160/train... 80 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 7174.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/mnist160/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/mnist160/test... 80 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 28315.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/mnist160/test.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.319G      2.475         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 20.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        0.1      0.488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.287G      2.453         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 10.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.138        0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.285G      2.385         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 10.35it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 37.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.05      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.002 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.2MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.2MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-cls summary (fused): 112 layers, 1,538,834 parameters, 0 gradients, 3.2 GFLOPs\n",
            "WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist160/train... found 80 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist160/test... found 80 images in 10 classes ‚úÖ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 14.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.138      0.512\n",
            "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : distinctive_reptile_1228\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/acsully/general/4f0de2e2fc1444db80defab800d1771d\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]                : (2.856e-05, 4.3054200000000005e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top1 [8] : (0.05, 0.13750000298023224)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/accuracy_top5 [8] : (0.4875, 0.5375)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 3.263\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 1543914\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 1.45\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [6]            : (2.38477, 2.4746)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/loss [6]              : (2.34701, 2.42057)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url                 : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fultralytics%2Fultralytics%2Fblob%2Fmain%2Fexamples%2Ftutorial.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : mnist160\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 224\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-cls.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/classify/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : classify\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 11\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (3.06 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 224x224 6 0.34, 9 0.11, 8 0.11, 4 0.09, 2 0.08, 7.9ms\n",
            "Speed: 13.4ms preprocess, 7.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: 'runs/classify/train2'\n",
              " speed: {'preprocess': 13.407230377197266, 'inference': 7.907867431640625, 'postprocess': 0.1049041748046875}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pose\n",
        "\n",
        "YOLO11 _pose_ models use the `-pose` suffix, i.e. `yolo11n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
      ],
      "metadata": {
        "id": "SpIaFLiO11TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-pose.pt')  # load a pretrained YOLO pose model\n",
        "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "si4aKFNg19vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8aece5-dde3-4a1d-b31c-5797d37f5b59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.97M/5.97M [00:00<00:00, 91.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolo11n-pose.pt, data=coco8-pose.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/pose/train\n",
            "\n",
            "Dataset 'coco8-pose.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/coco8-pose/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8-pose.zip to '/content/datasets/coco8-pose.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 334k/334k [00:00<00:00, 13.0MB/s]\n",
            "Unzipping /content/datasets/coco8-pose.zip to /content/datasets/coco8-pose...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 4306.43file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    715294  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO11n-pose summary: 344 layers, 2,874,462 parameters, 2,874,446 gradients, 7.5 GFLOPs\n",
            "\n",
            "Transferred 541/541 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/acsully/general/9e688b10541b48eeb7182ae27b6ff318\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/pose/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8-pose/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1245.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8-pose/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-pose/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 9473.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8-pose/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/pose/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/pose/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3     0.732G      1.301      3.165     0.4364      1.014      1.557         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.805      0.888      0.907      0.728      0.983      0.643      0.763      0.356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3     0.679G       1.67      4.103     0.3852      1.164      1.554          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.805      0.884      0.907      0.713      0.982      0.643      0.763       0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3     0.684G      1.411      3.936     0.4954      1.615      1.475         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.809      0.857      0.907      0.711      0.982      0.643      0.763      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.003 hours.\n",
            "Optimizer stripped from runs/pose/train/weights/last.pt, 6.1MB\n",
            "Optimizer stripped from runs/pose/train/weights/best.pt, 6.1MB\n",
            "\n",
            "Validating runs/pose/train/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-pose summary (fused): 257 layers, 2,866,468 parameters, 0 gradients, 7.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         14      0.806      0.889      0.907      0.713      0.983      0.643      0.763      0.356\n",
            "Speed: 0.8ms preprocess, 5.3ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : nice_dome_2918\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/acsully/general/9e688b10541b48eeb7182ae27b6ff318\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 1.36e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 1.36e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 1.36e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [8]     : (0.90686, 0.90712)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(P) [8]     : (0.76272, 0.7627806529764654)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.71054, 0.72775)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(P) [8]  : (0.35224, 0.36037)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.80476, 0.80865)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(P) [8] : (0.98173, 0.98273)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [8]    : (0.85714, 0.8892148450971981)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(P) [8]    : (0.6428571428571429, 0.64286)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 7.542\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2874462\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 36.022\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (1.30091, 1.67039)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (1.01359, 1.6154)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.47488, 1.55706)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/kobj_loss [6]      : (0.3852, 0.49542)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/pose_loss [6]      : (3.16475, 4.10297)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (0.8851, 0.8888)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (0.51344, 0.5166)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (1.09084, 1.09423)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/kobj_loss [6]        : (0.40356, 0.40538)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/pose_loss [6]        : (3.75107, 3.8024)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url                 : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fultralytics%2Fultralytics%2Fblob%2Fmain%2Fexamples%2Ftutorial.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/coco8-pose.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-pose.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/pose/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : pose\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 17\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.77 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 23.1ms\n",
            "Speed: 3.5ms preprocess, 23.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: ultralytics.engine.results.Keypoints object\n",
              " masks: None\n",
              " names: {0: 'person'}\n",
              " obb: None\n",
              " orig_img: array([[[119, 146, 172],\n",
              "         [121, 148, 174],\n",
              "         [122, 152, 177],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[120, 147, 173],\n",
              "         [122, 149, 175],\n",
              "         [123, 153, 178],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        [[123, 150, 176],\n",
              "         [124, 151, 177],\n",
              "         [125, 155, 180],\n",
              "         ...,\n",
              "         [161, 171, 188],\n",
              "         [160, 170, 187],\n",
              "         [160, 170, 187]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[183, 182, 186],\n",
              "         [179, 178, 182],\n",
              "         [180, 179, 183],\n",
              "         ...,\n",
              "         [121, 111, 117],\n",
              "         [113, 103, 109],\n",
              "         [115, 105, 111]],\n",
              " \n",
              "        [[165, 164, 168],\n",
              "         [173, 172, 176],\n",
              "         [187, 186, 190],\n",
              "         ...,\n",
              "         [102,  92,  98],\n",
              "         [101,  91,  97],\n",
              "         [103,  93,  99]],\n",
              " \n",
              "        [[123, 122, 126],\n",
              "         [145, 144, 148],\n",
              "         [176, 175, 179],\n",
              "         ...,\n",
              "         [ 95,  85,  91],\n",
              "         [ 96,  86,  92],\n",
              "         [ 98,  88,  94]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/pose/train2'\n",
              " speed: {'preprocess': 3.4837722778320312, 'inference': 23.113012313842773, 'postprocess': 2.5534629821777344}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Oriented Bounding Boxes (OBB)\n",
        "\n",
        "YOLO11 _OBB_ models use the `-obb` suffix, i.e. `yolo11n-obb.pt` and are pretrained on the DOTA dataset. See [OBB Docs](https://docs.ultralytics.com/tasks/obb/) for full details."
      ],
      "metadata": {
        "id": "cf5j_T9-B5F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11n-obb, train it on DOTA8 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n-obb.pt')  # load a pretrained YOLO OBB model\n",
        "model.train(data='dota8.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/boats.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "IJNKClOOB5YS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5772b2-3898-4074-9296-fca5eb234004"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-obb.pt to 'yolo11n-obb.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.53M/5.53M [00:00<00:00, 85.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolo11n-obb.pt, data=dota8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/train\n",
            "\n",
            "Dataset 'dota8.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/dota8/images/val'\n",
            "Downloading https://ultralytics.com/assets/dota8.zip to '/content/datasets/dota8.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.24M/1.24M [00:00<00:00, 26.3MB/s]\n",
            "Unzipping /content/datasets/dota8.zip to /content/datasets/dota8...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 1653.59file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (0.7s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=15\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    505264  ultralytics.nn.modules.head.OBB              [15, 1, [64, 128, 256]]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO11n-obb summary: 344 layers, 2,664,432 parameters, 2,664,416 gradients, 6.7 GFLOPs\n",
            "\n",
            "Transferred 541/541 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/acsully/general/4c22ec301339498b883f54e10957dcd0\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/obb/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/dota8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1955.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/dota8/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dota8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 355.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/dota8/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/obb/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/obb/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      1.67G     0.7456     0.6184      1.609         72       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4          8      0.946          1      0.995      0.804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3      1.77G     0.8826     0.5478       1.49        143       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4          8      0.945          1      0.995      0.804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3      1.63G     0.5578     0.4606      1.086         95       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4          8      0.959          1      0.995      0.804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.004 hours.\n",
            "Optimizer stripped from runs/obb/train/weights/last.pt, 5.9MB\n",
            "Optimizer stripped from runs/obb/train/weights/best.pt, 5.9MB\n",
            "\n",
            "Validating runs/obb/train/weights/best.pt...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-obb summary (fused): 257 layers, 2,656,648 parameters, 0 gradients, 6.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4          8      0.957          1      0.995      0.804\n",
            "      baseball diamond          3          4      0.892          1      0.995      0.851\n",
            "      basketball court          1          3       0.98          1      0.995      0.866\n",
            "     soccer ball field          1          1          1          1      0.995      0.697\n",
            "Speed: 0.5ms preprocess, 11.7ms inference, 0.0ms loss, 5.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/obb/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : surprising_brush_9917\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/acsully/general/4c22ec301339498b883f54e10957dcd0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [7]               : (0.0, 3.5768e-06)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [7]               : (0.0, 3.5768e-06)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [7]               : (0.0, 3.5768e-06)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B)         : 0.995\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [8]  : (0.80415, 0.80436)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [8] : (0.9451, 0.95928)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B)        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs             : 6.703\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters         : 2664432\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)  : 62.776\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [6]       : (0.55783, 0.88257)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [6]       : (0.46056, 0.61845)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [6]       : (1.08569, 1.60852)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [6]         : (0.78973, 0.80097)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [6]         : (0.40041, 0.40356)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [6]         : (2.12437, 2.139)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url                 : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fultralytics%2Fultralytics%2Fblob%2Fmain%2Fexamples%2Ftutorial.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crop_fraction   : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : /usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/dota8.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 1024\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11n-obb.pt\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs/obb/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_hybrid     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : obb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 13\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (5.62 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 151 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading https://ultralytics.com/images/boats.jpg to 'boats.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190k/190k [00:00<00:00, 8.98MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/boats.jpg: 576x1024 58.1ms\n",
            "Speed: 4.8ms preprocess, 58.1ms inference, 8.9ms postprocess per image at shape (1, 3, 576, 1024)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'plane', 1: 'ship', 2: 'storage tank', 3: 'baseball diamond', 4: 'tennis court', 5: 'basketball court', 6: 'ground track field', 7: 'harbor', 8: 'bridge', 9: 'large vehicle', 10: 'small vehicle', 11: 'helicopter', 12: 'roundabout', 13: 'soccer ball field', 14: 'swimming pool'}\n",
              " obb: ultralytics.engine.results.OBB object\n",
              " orig_img: array([[[ 40,  68, 103],\n",
              "         [ 29,  56,  90],\n",
              "         [ 14,  36,  64],\n",
              "         ...,\n",
              "         [ 86, 100,  94],\n",
              "         [ 88, 102,  96],\n",
              "         [ 92, 106, 100]],\n",
              " \n",
              "        [[ 64,  95, 128],\n",
              "         [ 54,  83, 114],\n",
              "         [ 39,  66,  92],\n",
              "         ...,\n",
              "         [ 83,  97,  91],\n",
              "         [ 82,  96,  90],\n",
              "         [ 82,  96,  90]],\n",
              " \n",
              "        [[ 77, 117, 142],\n",
              "         [ 73, 111, 135],\n",
              "         [ 69, 103, 126],\n",
              "         ...,\n",
              "         [ 62,  74,  68],\n",
              "         [ 64,  78,  72],\n",
              "         [ 65,  79,  73]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 62,  60,  52],\n",
              "         [ 63,  61,  53],\n",
              "         [ 58,  56,  48],\n",
              "         ...,\n",
              "         [ 24,  32,   9],\n",
              "         [ 24,  32,   9],\n",
              "         [ 24,  32,   9]],\n",
              " \n",
              "        [[ 62,  60,  52],\n",
              "         [ 63,  61,  53],\n",
              "         [ 60,  58,  50],\n",
              "         ...,\n",
              "         [ 24,  32,   9],\n",
              "         [ 24,  32,   9],\n",
              "         [ 24,  32,   9]],\n",
              " \n",
              "        [[ 61,  59,  51],\n",
              "         [ 64,  62,  54],\n",
              "         [ 63,  61,  53],\n",
              "         ...,\n",
              "         [ 24,  32,   9],\n",
              "         [ 24,  32,   9],\n",
              "         [ 24,  32,   9]]], dtype=uint8)\n",
              " orig_shape: (1080, 1920)\n",
              " path: '/content/boats.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/obb/train2'\n",
              " speed: {'preprocess': 4.8274993896484375, 'inference': 58.09664726257324, 'postprocess': 8.858203887939453}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install from source\n",
        "!pip install git+https://github.com/ultralytics/ultralytics@main"
      ],
      "metadata": {
        "id": "pIdE6i8C3LYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e480c750-a0cf-4089-bb71-327b6ced4b8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ultralytics/ultralytics@main\n",
            "  Cloning https://github.com/ultralytics/ultralytics (to revision main) to /tmp/pip-req-build-vonuv2ga\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics /tmp/pip-req-build-vonuv2ga\n",
            "  Resolved https://github.com/ultralytics/ultralytics to commit c1860b833361c9f88e53e522c3b8530e5ff698a6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics==8.3.72) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.72) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.72) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics==8.3.72) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.72) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.72) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.72) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics==8.3.72) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics==8.3.72) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.72) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.72) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.72) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone and run tests on updates branch\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "%pip install -qe ultralytics"
      ],
      "metadata": {
        "id": "uRKlwxSJdhd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b817fb-9345-4a2f-b4ed-55bbdfcfb62d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 50246, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 50246 (delta 49), reused 50 (delta 27), pack-reused 50164 (from 1)\u001b[K\n",
            "Receiving objects: 100% (50246/50246), 28.55 MiB | 15.62 MiB/s, done.\n",
            "Resolving deltas: 100% (37191/37191), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests (Git clone only)\n",
        "!pytest ultralytics/tests"
      ],
      "metadata": {
        "id": "GtPlh7mcCGZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76a42a8-c520-4fb7-9576-bae26b493775"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.11.11, pytest-8.3.4, pluggy-1.5.0\n",
            "rootdir: /content/ultralytics\n",
            "configfile: pyproject.toml\n",
            "plugins: langsmith-0.3.4, anyio-3.7.1, typeguard-4.4.1\n",
            "collected 358 items                                                                                \u001b[0m\n",
            "\n",
            "ultralytics/tests/test_cli.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                       [ 24%]\u001b[0m\n",
            "ultralytics/tests/test_cuda.py \u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                         [ 29%]\u001b[0m\n",
            "ultralytics/tests/test_engine.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                       [ 34%]\u001b[0m\n",
            "ultralytics/tests/test_exports.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[33ms\u001b[0m\u001b[33ms\u001b[0m\u001b[31m                                                   [ 42%]\u001b[0m\n",
            "ultralytics/tests/test_integrations.py \u001b[33ms\u001b[0m\u001b[33ms\u001b[0m\u001b[33ms\u001b[0m\u001b[33ms\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                 [ 47%]\u001b[0m\n",
            "ultralytics/tests/test_python.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33ms\u001b[0m\u001b[33ms\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m         [100%]\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________________ test_checks ____________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_checks\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Validate CUDA settings against torch CUDA functions.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m torch.cuda.is_available() == CUDA_IS_AVAILABLE\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert False == True\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +  where False = <function is_available at 0x7ff62d950400>()\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +    where <function is_available at 0x7ff62d950400> = <module 'torch.cuda' from '/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py'>.is_available\u001b[0m\n",
            "\u001b[1m\u001b[31mE        +      where <module 'torch.cuda' from '/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py'> = torch.cuda\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/tests/test_cuda.py\u001b[0m:18: AssertionError\n",
            "\u001b[31m\u001b[1m_____________________________________________ test_amp _____________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.skipif(\u001b[95mnot\u001b[39;49;00m CUDA_IS_AVAILABLE, reason=\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA is not available\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_amp\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test AMP training checks.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       model = YOLO(\u001b[33m\"\u001b[39;49;00m\u001b[33myolo11n.pt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).model.cuda()\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/tests/test_cuda.py\u001b[0m:25: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:1050: in cuda\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._apply(\u001b[94mlambda\u001b[39;49;00m t: t.cuda(device))\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/nn/tasks.py\u001b[0m:252: in _apply\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m = \u001b[96msuper\u001b[39;49;00m()._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:900: in _apply\n",
            "    \u001b[0mmodule._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:900: in _apply\n",
            "    \u001b[0mmodule._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:900: in _apply\n",
            "    \u001b[0mmodule._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:927: in _apply\n",
            "    \u001b[0mparam_applied = fn(param)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:1050: in <lambda>\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._apply(\u001b[94mlambda\u001b[39;49;00m t: t.cuda(device))\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92m_lazy_init\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mglobal\u001b[39;49;00m _initialized, _queued_calls\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m is_initialized() \u001b[95mor\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(_tls, \u001b[33m\"\u001b[39;49;00m\u001b[33mis_initializing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m _initialization_lock:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# We be double-checked locking, boys!  This is OK because\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# the above test was GIL protected anyway.  The inner test\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# is for when a thread blocked on some other thread which was\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# doing the initialization; when they get the lock, they will\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# find there is nothing left to do.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m is_initialized():\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# It is important to prevent other threads from entering _lazy_init\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# immediately, while we are still guaranteed to have the GIL, because some\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# of the C calls we make below will release the GIL\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m _is_in_bad_fork():\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m \u001b[96mRuntimeError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mmultiprocessing, you must use the \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m start method\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(torch._C, \u001b[33m\"\u001b[39;49;00m\u001b[33m_cuda_getDeviceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mTorch not compiled with CUDA enabled\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m _cudart \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# This function throws if there's a driver initialization error, no GPUs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# are found or any other error occurs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_MODULE_LOADING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m os.environ:\u001b[90m\u001b[39;49;00m\n",
            "                os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_MODULE_LOADING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33mLAZY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           torch._C._cuda_init()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: No CUDA GPUs are available\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m:319: RuntimeError\n",
            "\u001b[31m\u001b[1m____________________________________________ test_train ____________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.skipif(\u001b[95mnot\u001b[39;49;00m CUDA_IS_AVAILABLE, reason=\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA is not available\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_train\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test model training on a minimal dataset using available CUDA devices.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        device = \u001b[94m0\u001b[39;49;00m \u001b[94mif\u001b[39;49;00m CUDA_DEVICE_COUNT == \u001b[94m1\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m [\u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
            ">       YOLO(MODEL).train(data=\u001b[33m\"\u001b[39;49;00m\u001b[33mcoco8.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, imgsz=\u001b[94m64\u001b[39;49;00m, epochs=\u001b[94m1\u001b[39;49;00m, device=device)  \u001b[90m# requires imgsz>=64\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/tests/test_cuda.py\u001b[0m:64: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31multralytics/ultralytics/engine/model.py\u001b[0m:802: in train\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.trainer = (trainer \u001b[95mor\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._smart_load(\u001b[33m\"\u001b[39;49;00m\u001b[33mtrainer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))(overrides=args, _callbacks=\u001b[96mself\u001b[39;49;00m.callbacks)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/engine/trainer.py\u001b[0m:103: in __init__\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.device = select_device(\u001b[96mself\u001b[39;49;00m.args.device, \u001b[96mself\u001b[39;49;00m.args.batch)\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "device = '0', batch = 16, newline = False, verbose = True\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mselect_device\u001b[39;49;00m(device=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, batch=\u001b[94m0\u001b[39;49;00m, newline=\u001b[94mFalse\u001b[39;49;00m, verbose=\u001b[94mTrue\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    Selects the appropriate PyTorch device based on the provided arguments.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    The function takes a string specifying the device or a torch.device object and returns a torch.device object\u001b[39;49;00m\n",
            "    \u001b[33m    representing the selected device. The function also validates the number of available devices and raises an\u001b[39;49;00m\n",
            "    \u001b[33m    exception if the requested device(s) are not available.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        device (str | torch.device, optional): Device string or torch.device object.\u001b[39;49;00m\n",
            "    \u001b[33m            Options are 'None', 'cpu', or 'cuda', or '0' or '0,1,2,3'. Defaults to an empty string, which auto-selects\u001b[39;49;00m\n",
            "    \u001b[33m            the first available GPU, or CPU if no GPU is available.\u001b[39;49;00m\n",
            "    \u001b[33m        batch (int, optional): Batch size being used in your model. Defaults to 0.\u001b[39;49;00m\n",
            "    \u001b[33m        newline (bool, optional): If True, adds a newline at the end of the log string. Defaults to False.\u001b[39;49;00m\n",
            "    \u001b[33m        verbose (bool, optional): If True, logs the device information. Defaults to True.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns:\u001b[39;49;00m\n",
            "    \u001b[33m        (torch.device): Selected device.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Raises:\u001b[39;49;00m\n",
            "    \u001b[33m        ValueError: If the specified device is not available or if the batch size is not a multiple of the number of\u001b[39;49;00m\n",
            "    \u001b[33m            devices when using multiple GPUs.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Examples:\u001b[39;49;00m\n",
            "    \u001b[33m        >>> select_device(\"cuda:0\")\u001b[39;49;00m\n",
            "    \u001b[33m        device(type='cuda', index=0)\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m        >>> select_device(\"cpu\")\u001b[39;49;00m\n",
            "    \u001b[33m        device(type='cpu')\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Note:\u001b[39;49;00m\n",
            "    \u001b[33m        Sets the 'CUDA_VISIBLE_DEVICES' environment variable for specifying which GPUs to use.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(device, torch.device) \u001b[95mor\u001b[39;49;00m \u001b[96mstr\u001b[39;49;00m(device).startswith(\u001b[33m\"\u001b[39;49;00m\u001b[33mtpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m device\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        s = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUltralytics \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m__version__\u001b[33m}\u001b[39;49;00m\u001b[33m üöÄ Python-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mPYTHON_VERSION\u001b[33m}\u001b[39;49;00m\u001b[33m torch-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtorch.__version__\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        device = \u001b[96mstr\u001b[39;49;00m(device).lower()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m remove \u001b[95min\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mnone\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m(\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m[\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m]\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            device = device.replace(remove, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)  \u001b[90m# to string, 'cuda:0' -> '0' and '(0, 1)' -> '0,1'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        cpu = device == \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        mps = device \u001b[95min\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33mmps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmps:0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}  \u001b[90m# Apple Metal Performance Shaders (MPS)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m cpu \u001b[95mor\u001b[39;49;00m mps:\u001b[90m\u001b[39;49;00m\n",
            "            os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33m-1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m  \u001b[90m# force torch.cuda.is_available() = False\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melif\u001b[39;49;00m device:  \u001b[90m# non-cpu device requested\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m device == \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                device = \u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m device:\u001b[90m\u001b[39;49;00m\n",
            "                device = \u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.join([x \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m device.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mif\u001b[39;49;00m x])  \u001b[90m# remove sequential commas, i.e. \"0,,1\" -> \"0,1\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            visible = os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "            os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = device  \u001b[90m# set environment variable - must be before assert is_available()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (torch.cuda.is_available() \u001b[95mand\u001b[39;49;00m torch.cuda.device_count() >= \u001b[96mlen\u001b[39;49;00m(device.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))):\u001b[90m\u001b[39;49;00m\n",
            "                LOGGER.info(s)\u001b[90m\u001b[39;49;00m\n",
            "                install = (\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA devices are seen by torch.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[94mif\u001b[39;49;00m torch.cuda.device_count() == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[94melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid CUDA \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdevice\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m requested.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m Use \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=cpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m or pass valid CUDA device(s) if available,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m i.e. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m or \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=0,1,2,3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m for Multi-GPU.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mtorch.cuda.is_available(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtorch.cuda.is_available()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mtorch.cuda.device_count(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtorch.cuda.device_count()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mos.environ[\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m]: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvisible\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00minstall\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE               ValueError: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\u001b[0m\n",
            "\u001b[1m\u001b[31mE               \u001b[0m\n",
            "\u001b[1m\u001b[31mE               torch.cuda.is_available(): False\u001b[0m\n",
            "\u001b[1m\u001b[31mE               torch.cuda.device_count(): 1\u001b[0m\n",
            "\u001b[1m\u001b[31mE               os.environ['CUDA_VISIBLE_DEVICES']: -1\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/utils/torch_utils.py\u001b[0m:188: ValueError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'weights/path with spaces/yolo11n.pt'...\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 \n",
            "--------------------------------------- Captured stderr call ---------------------------------------\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 43.2MB/s]\n",
            "\u001b[31m\u001b[1m__________________________________________ test_autobatch __________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.skipif(\u001b[95mnot\u001b[39;49;00m CUDA_IS_AVAILABLE, reason=\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA is not available\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_autobatch\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Check optimal batch size for YOLO model training using autobatch utility.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96multralytics\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mutils\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mautobatch\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m check_train_batch_size\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       check_train_batch_size(YOLO(MODEL).model.cuda(), imgsz=\u001b[94m128\u001b[39;49;00m, amp=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/tests/test_cuda.py\u001b[0m:98: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:1050: in cuda\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._apply(\u001b[94mlambda\u001b[39;49;00m t: t.cuda(device))\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/nn/tasks.py\u001b[0m:252: in _apply\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m = \u001b[96msuper\u001b[39;49;00m()._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:900: in _apply\n",
            "    \u001b[0mmodule._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:900: in _apply\n",
            "    \u001b[0mmodule._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:900: in _apply\n",
            "    \u001b[0mmodule._apply(fn)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:927: in _apply\n",
            "    \u001b[0mparam_applied = fn(param)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m:1050: in <lambda>\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._apply(\u001b[94mlambda\u001b[39;49;00m t: t.cuda(device))\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92m_lazy_init\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mglobal\u001b[39;49;00m _initialized, _queued_calls\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m is_initialized() \u001b[95mor\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(_tls, \u001b[33m\"\u001b[39;49;00m\u001b[33mis_initializing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m _initialization_lock:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# We be double-checked locking, boys!  This is OK because\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# the above test was GIL protected anyway.  The inner test\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# is for when a thread blocked on some other thread which was\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# doing the initialization; when they get the lock, they will\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# find there is nothing left to do.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m is_initialized():\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# It is important to prevent other threads from entering _lazy_init\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# immediately, while we are still guaranteed to have the GIL, because some\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# of the C calls we make below will release the GIL\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m _is_in_bad_fork():\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m \u001b[96mRuntimeError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mmultiprocessing, you must use the \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mspawn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m start method\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96mhasattr\u001b[39;49;00m(torch._C, \u001b[33m\"\u001b[39;49;00m\u001b[33m_cuda_getDeviceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mTorch not compiled with CUDA enabled\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m _cudart \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# This function throws if there's a driver initialization error, no GPUs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[90m# are found or any other error occurs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_MODULE_LOADING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m os.environ:\u001b[90m\u001b[39;49;00m\n",
            "                os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_MODULE_LOADING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33mLAZY\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">           torch._C._cuda_init()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           RuntimeError: No CUDA GPUs are available\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m:319: RuntimeError\n",
            "\u001b[31m\u001b[1m_________________________________________ test_predict_sam _________________________________________\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.skipif(\u001b[95mnot\u001b[39;49;00m CUDA_IS_AVAILABLE, reason=\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA is not available\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_predict_sam\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Test SAM model predictions using different prompts, including bounding boxes and point annotations.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96multralytics\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m SAM\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfrom\u001b[39;49;00m \u001b[04m\u001b[96multralytics\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mmodels\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96msam\u001b[39;49;00m \u001b[94mimport\u001b[39;49;00m Predictor \u001b[94mas\u001b[39;49;00m SAMPredictor\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Load a model\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        model = SAM(WEIGHTS_DIR / \u001b[33m\"\u001b[39;49;00m\u001b[33msam2.1_b.pt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Display model information (optional)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        model.info()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Run inference\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">       model(SOURCE, device=\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/tests/test_cuda.py\u001b[0m:125: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31multralytics/ultralytics/models/sam/model.py\u001b[0m:137: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.predict(source, stream, bboxes, points, labels, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/models/sam/model.py\u001b[0m:111: in predict\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96msuper\u001b[39;49;00m().predict(source, stream, prompts=prompts, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/engine/model.py\u001b[0m:551: in predict\n",
            "    \u001b[0m\u001b[96mself\u001b[39;49;00m.predictor.setup_model(model=\u001b[96mself\u001b[39;49;00m.model, verbose=is_cli)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/models/sam/predict.py\u001b[0m:424: in setup_model\n",
            "    \u001b[0mdevice = select_device(\u001b[96mself\u001b[39;49;00m.args.device, verbose=verbose)\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "device = '0', batch = 0, newline = False, verbose = False\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mselect_device\u001b[39;49;00m(device=\u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, batch=\u001b[94m0\u001b[39;49;00m, newline=\u001b[94mFalse\u001b[39;49;00m, verbose=\u001b[94mTrue\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
            "    \u001b[33m    Selects the appropriate PyTorch device based on the provided arguments.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    The function takes a string specifying the device or a torch.device object and returns a torch.device object\u001b[39;49;00m\n",
            "    \u001b[33m    representing the selected device. The function also validates the number of available devices and raises an\u001b[39;49;00m\n",
            "    \u001b[33m    exception if the requested device(s) are not available.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Args:\u001b[39;49;00m\n",
            "    \u001b[33m        device (str | torch.device, optional): Device string or torch.device object.\u001b[39;49;00m\n",
            "    \u001b[33m            Options are 'None', 'cpu', or 'cuda', or '0' or '0,1,2,3'. Defaults to an empty string, which auto-selects\u001b[39;49;00m\n",
            "    \u001b[33m            the first available GPU, or CPU if no GPU is available.\u001b[39;49;00m\n",
            "    \u001b[33m        batch (int, optional): Batch size being used in your model. Defaults to 0.\u001b[39;49;00m\n",
            "    \u001b[33m        newline (bool, optional): If True, adds a newline at the end of the log string. Defaults to False.\u001b[39;49;00m\n",
            "    \u001b[33m        verbose (bool, optional): If True, logs the device information. Defaults to True.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns:\u001b[39;49;00m\n",
            "    \u001b[33m        (torch.device): Selected device.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Raises:\u001b[39;49;00m\n",
            "    \u001b[33m        ValueError: If the specified device is not available or if the batch size is not a multiple of the number of\u001b[39;49;00m\n",
            "    \u001b[33m            devices when using multiple GPUs.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Examples:\u001b[39;49;00m\n",
            "    \u001b[33m        >>> select_device(\"cuda:0\")\u001b[39;49;00m\n",
            "    \u001b[33m        device(type='cuda', index=0)\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m        >>> select_device(\"cpu\")\u001b[39;49;00m\n",
            "    \u001b[33m        device(type='cpu')\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Note:\u001b[39;49;00m\n",
            "    \u001b[33m        Sets the 'CUDA_VISIBLE_DEVICES' environment variable for specifying which GPUs to use.\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(device, torch.device) \u001b[95mor\u001b[39;49;00m \u001b[96mstr\u001b[39;49;00m(device).startswith(\u001b[33m\"\u001b[39;49;00m\u001b[33mtpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m device\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        s = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mUltralytics \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m__version__\u001b[33m}\u001b[39;49;00m\u001b[33m üöÄ Python-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mPYTHON_VERSION\u001b[33m}\u001b[39;49;00m\u001b[33m torch-\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtorch.__version__\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        device = \u001b[96mstr\u001b[39;49;00m(device).lower()\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m remove \u001b[95min\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mnone\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m(\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m[\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m]\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            device = device.replace(remove, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)  \u001b[90m# to string, 'cuda:0' -> '0' and '(0, 1)' -> '0,1'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        cpu = device == \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        mps = device \u001b[95min\u001b[39;49;00m {\u001b[33m\"\u001b[39;49;00m\u001b[33mmps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmps:0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}  \u001b[90m# Apple Metal Performance Shaders (MPS)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m cpu \u001b[95mor\u001b[39;49;00m mps:\u001b[90m\u001b[39;49;00m\n",
            "            os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33m-1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m  \u001b[90m# force torch.cuda.is_available() = False\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melif\u001b[39;49;00m device:  \u001b[90m# non-cpu device requested\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m device == \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                device = \u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95min\u001b[39;49;00m device:\u001b[90m\u001b[39;49;00m\n",
            "                device = \u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.join([x \u001b[94mfor\u001b[39;49;00m x \u001b[95min\u001b[39;49;00m device.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mif\u001b[39;49;00m x])  \u001b[90m# remove sequential commas, i.e. \"0,,1\" -> \"0,1\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            visible = os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "            os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = device  \u001b[90m# set environment variable - must be before assert is_available()\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (torch.cuda.is_available() \u001b[95mand\u001b[39;49;00m torch.cuda.device_count() >= \u001b[96mlen\u001b[39;49;00m(device.split(\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))):\u001b[90m\u001b[39;49;00m\n",
            "                LOGGER.info(s)\u001b[90m\u001b[39;49;00m\n",
            "                install = (\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA devices are seen by torch.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[94mif\u001b[39;49;00m torch.cuda.device_count() == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[94melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid CUDA \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdevice\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m requested.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m Use \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=cpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m or pass valid CUDA device(s) if available,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m i.e. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m or \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdevice=0,1,2,3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m for Multi-GPU.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mtorch.cuda.is_available(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtorch.cuda.is_available()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mtorch.cuda.device_count(): \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtorch.cuda.device_count()\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mos.environ[\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m]: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvisible\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00minstall\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE               ValueError: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\u001b[0m\n",
            "\u001b[1m\u001b[31mE               \u001b[0m\n",
            "\u001b[1m\u001b[31mE               torch.cuda.is_available(): False\u001b[0m\n",
            "\u001b[1m\u001b[31mE               torch.cuda.device_count(): 1\u001b[0m\n",
            "\u001b[1m\u001b[31mE               os.environ['CUDA_VISIBLE_DEVICES']: 0\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31multralytics/ultralytics/utils/torch_utils.py\u001b[0m:188: ValueError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/sam2.1_b.pt to 'weights/sam2.1_b.pt'...\n",
            "Model summary: 566 layers, 80,850,178 parameters, 80,850,178 gradients\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 \n",
            "--------------------------------------- Captured stderr call ---------------------------------------\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154M/154M [00:01<00:00, 85.6MB/s]\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "tests/test_exports.py::test_export_openvino\n",
            "  <frozen importlib.util>:262: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "======================================= slowest 30 durations =======================================\n",
            "87.93s call     tests/test_cli.py::test_fastsam\n",
            "74.63s call     tests/test_python.py::test_yolo_world\n",
            "53.03s call     tests/test_exports.py::test_export_tflite\n",
            "42.05s call     tests/test_cli.py::test_rtdetr\n",
            "41.20s call     tests/test_python.py::test_all_model_yamls\n",
            "33.56s call     tests/test_exports.py::test_export_onnx\n",
            "32.54s call     tests/test_engine.py::test_export\n",
            "25.36s call     tests/test_cli.py::test_train[segment-model4-coco8-seg.yaml]\n",
            "25.02s call     tests/test_engine.py::test_detect\n",
            "24.92s call     tests/test_cli.py::test_train[detect-model2-coco8.yaml]\n",
            "24.28s call     tests/test_cli.py::test_train[pose-model0-coco8-pose.yaml]\n",
            "23.04s call     tests/test_python.py::test_track_stream\n",
            "21.19s call     tests/test_integrations.py::test_pycocotools\n",
            "19.80s call     tests/test_engine.py::test_segment\n",
            "19.63s call     tests/test_cli.py::test_train[obb-model1-dota8.yaml]\n",
            "19.33s call     tests/test_python.py::test_workflow\n",
            "18.34s call     tests/test_python.py::test_yolov10\n",
            "17.17s call     tests/test_cli.py::test_special_modes\n",
            "14.37s call     tests/test_cli.py::test_train[classify-model3-imagenet10]\n",
            "14.13s call     tests/test_python.py::test_predict_visualize[yolo11n.pt]\n",
            "14.11s call     tests/test_exports.py::test_export_coreml\n",
            "13.52s call     tests/test_python.py::test_predict_visualize[yolo11n-pose.pt]\n",
            "13.11s call     tests/test_python.py::test_train_pretrained\n",
            "12.98s call     tests/test_python.py::test_predict_visualize[yolo11n-obb.pt]\n",
            "12.43s call     tests/test_python.py::test_predict_visualize[yolo11n-seg.pt]\n",
            "12.05s call     tests/test_python.py::test_train_scratch\n",
            "10.90s call     tests/test_exports.py::test_export_openvino\n",
            "10.90s call     tests/test_cli.py::test_val[segment-model4-coco8-seg.yaml]\n",
            "10.40s call     tests/test_cli.py::test_val[classify-model3-imagenet10]\n",
            "9.91s call     tests/test_python.py::test_data_annotator\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m ultralytics/tests/test_cuda.py::\u001b[1mtest_checks\u001b[0m - AssertionError: assert False == True\n",
            "\u001b[31mFAILED\u001b[0m ultralytics/tests/test_cuda.py::\u001b[1mtest_amp\u001b[0m - RuntimeError: No CUDA GPUs are available\n",
            "\u001b[31mFAILED\u001b[0m ultralytics/tests/test_cuda.py::\u001b[1mtest_train\u001b[0m - ValueError: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if...\n",
            "\u001b[31mFAILED\u001b[0m ultralytics/tests/test_cuda.py::\u001b[1mtest_autobatch\u001b[0m - RuntimeError: No CUDA GPUs are available\n",
            "\u001b[31mFAILED\u001b[0m ultralytics/tests/test_cuda.py::\u001b[1mtest_predict_sam\u001b[0m - ValueError: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if...\n",
            "\u001b[31m================== \u001b[31m\u001b[1m5 failed\u001b[0m, \u001b[32m84 passed\u001b[0m, \u001b[33m9 skipped\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 895.10s (0:14:55)\u001b[0m\u001b[31m ==================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolo11{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05c8885-eda5-49b3-c3cc-6056850690c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/labels/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:14<00:00, 349.25it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/labels/val2017.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "                   all       5000      36335      0.653      0.504      0.549      0.393\n",
            "                person       2693      10777       0.76      0.676      0.753      0.524\n",
            "               bicycle        149        314      0.692      0.404      0.478      0.276\n",
            "                   car        535       1918      0.662      0.532      0.585      0.376\n",
            "            motorcycle        159        367      0.765      0.599      0.674      0.444\n",
            "              airplane         97        143      0.803      0.797      0.869      0.689\n",
            "                   bus        189        283      0.772      0.707      0.773      0.651\n",
            "                 train        157        190      0.827      0.811      0.863      0.681\n",
            "                 truck        250        414      0.585      0.415      0.477      0.322\n",
            "                  boat        121        424       0.58      0.351      0.413       0.22\n",
            "         traffic light        191        634      0.647      0.345      0.416      0.218\n",
            "          fire hydrant         86        101      0.867      0.743      0.806      0.639\n",
            "             stop sign         69         75      0.712      0.613      0.662      0.601\n",
            "         parking meter         37         60      0.698       0.55      0.613      0.467\n",
            "                 bench        235        411      0.575       0.28      0.325      0.217\n",
            "                  bird        125        427      0.618      0.382       0.44       0.28\n",
            "                   cat        184        202      0.782      0.861      0.882      0.703\n",
            "                   dog        177        218      0.761      0.743      0.779      0.648\n",
            "                 horse        128        272      0.764      0.706       0.77      0.592\n",
            "                 sheep         65        354        0.7      0.689      0.744      0.506\n",
            "                   cow         87        372      0.719      0.679      0.732      0.522\n",
            "              elephant         89        252      0.729      0.837      0.842      0.655\n",
            "                  bear         49         71      0.851      0.859      0.911      0.745\n",
            "                 zebra         85        266      0.804      0.838      0.893      0.673\n",
            "               giraffe        101        232      0.859      0.845      0.891        0.7\n",
            "              backpack        228        371      0.491      0.197      0.202      0.106\n",
            "              umbrella        174        407      0.652      0.537      0.581      0.392\n",
            "               handbag        292        540      0.476      0.128      0.165     0.0887\n",
            "                   tie        145        252      0.635      0.417       0.45       0.28\n",
            "              suitcase        105        299      0.636      0.472      0.536      0.375\n",
            "               frisbee         84        115      0.787      0.783      0.814      0.613\n",
            "                  skis        120        241      0.578      0.336      0.397      0.214\n",
            "             snowboard         49         69      0.584      0.377      0.393      0.275\n",
            "           sports ball        169        260      0.692      0.488      0.511      0.372\n",
            "                  kite         91        327       0.64      0.541      0.599      0.412\n",
            "          baseball bat         97        145      0.571      0.393      0.417      0.231\n",
            "        baseball glove        100        148      0.682        0.5      0.539      0.323\n",
            "            skateboard        127        179      0.706      0.648      0.678      0.467\n",
            "             surfboard        149        267      0.645      0.498       0.54      0.344\n",
            "         tennis racket        167        225      0.747      0.671      0.697      0.418\n",
            "                bottle        379       1013      0.622      0.414      0.471      0.312\n",
            "            wine glass        110        341      0.706      0.334      0.428       0.28\n",
            "                   cup        390        895      0.581      0.448      0.501      0.363\n",
            "                  fork        155        215      0.588      0.339      0.384      0.269\n",
            "                 knife        181        325      0.462      0.151      0.202      0.122\n",
            "                 spoon        153        253      0.398      0.154      0.162     0.0994\n",
            "                  bowl        314        623      0.608      0.496      0.528      0.392\n",
            "                banana        103        370      0.499      0.297      0.362      0.225\n",
            "                 apple         76        236      0.399      0.237      0.235      0.167\n",
            "              sandwich         98        177       0.56      0.503      0.483      0.363\n",
            "                orange         85        285      0.473      0.399      0.389      0.301\n",
            "              broccoli         71        312      0.498      0.356      0.385      0.213\n",
            "                carrot         81        365      0.438      0.323      0.289      0.179\n",
            "               hot dog         51        125      0.649      0.464      0.494      0.356\n",
            "                 pizza        153        284      0.703      0.641       0.69      0.523\n",
            "                 donut         62        328      0.611      0.507      0.549      0.427\n",
            "                  cake        124        310      0.601      0.439      0.521      0.359\n",
            "                 chair        580       1771      0.592      0.363       0.42      0.265\n",
            "                 couch        195        261      0.623      0.582      0.632      0.476\n",
            "          potted plant        172        342      0.549      0.395      0.395      0.228\n",
            "                   bed        149        163      0.627      0.619      0.661      0.484\n",
            "          dining table        501        695      0.545      0.449      0.449      0.312\n",
            "                toilet        149        179      0.732      0.763      0.822      0.668\n",
            "                    tv        207        288      0.721       0.67      0.725      0.548\n",
            "                laptop        183        231      0.668       0.68      0.713      0.591\n",
            "                 mouse         88        106      0.716      0.717      0.739      0.543\n",
            "                remote        145        283      0.507      0.279      0.323       0.19\n",
            "              keyboard        106        153      0.636      0.582      0.641      0.482\n",
            "            cell phone        214        262      0.588      0.431       0.44      0.305\n",
            "             microwave         54         55      0.681        0.6       0.67      0.521\n",
            "                  oven        115        143      0.637       0.49      0.556      0.383\n",
            "               toaster          8          9          1      0.427      0.691      0.455\n",
            "                  sink        187        225      0.662      0.511      0.542      0.368\n",
            "          refrigerator        101        126      0.769      0.643      0.724      0.574\n",
            "                  book        230       1129        0.5      0.118      0.218      0.108\n",
            "                 clock        204        267      0.755      0.625      0.657      0.462\n",
            "                  vase        137        274      0.589      0.478      0.478      0.328\n",
            "              scissors         28         36      0.529      0.306      0.327      0.276\n",
            "            teddy bear         94        190      0.688      0.574      0.627      0.458\n",
            "            hair drier          9         11          1          0    0.00103   0.000207\n",
            "            toothbrush         34         57       0.47      0.281      0.252      0.165\n",
            "Speed: 5.0ms preprocess, 187.8ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Saving runs/detect/val2/predictions.json...\n",
            "\n",
            "Evaluating pycocotools mAP using runs/detect/val2/predictions.json and /content/datasets/coco/annotations/instances_val2017.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.48s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=2.26s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=65.37s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=13.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.553\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.598\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.781\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt'...\n",
            "100% 18.4M/18.4M [00:00<00:00, 169MB/s]\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11s summary (fused): 238 layers, 9,443,760 parameters, 0 gradients, 21.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/labels/val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 313/313 [45:30<00:00,  8.72s/it]\n",
            "                   all       5000      36335      0.704      0.576      0.635      0.468\n",
            "                person       2693      10777      0.809      0.722      0.808      0.587\n",
            "               bicycle        149        314      0.737      0.478      0.572      0.346\n",
            "                   car        535       1918      0.732      0.593      0.678      0.461\n",
            "            motorcycle        159        367      0.783      0.668       0.75        0.5\n",
            "              airplane         97        143       0.87      0.886      0.937      0.764\n",
            "                   bus        189        283      0.843       0.77      0.858      0.731\n",
            "                 train        157        190      0.872      0.862      0.933      0.764\n",
            "                 truck        250        414      0.624        0.5       0.58      0.414\n",
            "                  boat        121        424      0.681      0.418      0.519      0.302\n",
            "         traffic light        191        634      0.685      0.426      0.497      0.269\n",
            "          fire hydrant         86        101      0.883      0.792      0.868       0.71\n",
            "             stop sign         69         75      0.788       0.68      0.731      0.667\n",
            "         parking meter         37         60       0.75       0.65      0.713      0.562\n",
            "                 bench        235        411      0.562       0.36      0.396      0.278\n",
            "                  bird        125        427      0.719      0.466      0.535      0.365\n",
            "                   cat        184        202      0.869      0.881      0.922      0.763\n",
            "                   dog        177        218      0.808      0.789       0.82      0.714\n",
            "                 horse        128        272      0.811      0.783       0.84      0.655\n",
            "                 sheep         65        354      0.739      0.734      0.785      0.578\n",
            "                   cow         87        372      0.798      0.743      0.795      0.598\n",
            "              elephant         89        252      0.774      0.883      0.878      0.698\n",
            "                  bear         49         71      0.865      0.905      0.932      0.787\n",
            "                 zebra         85        266       0.87      0.846      0.915      0.731\n",
            "               giraffe        101        232      0.908      0.892      0.931      0.761\n",
            "              backpack        228        371      0.513      0.245      0.281       0.16\n",
            "              umbrella        174        407      0.717      0.602      0.662      0.463\n",
            "               handbag        292        540      0.588      0.244      0.301       0.17\n",
            "                   tie        145        252      0.758       0.44      0.538      0.358\n",
            "              suitcase        105        299      0.703      0.579      0.675      0.465\n",
            "               frisbee         84        115      0.859      0.817       0.86      0.685\n",
            "                  skis        120        241      0.677      0.436      0.503       0.29\n",
            "             snowboard         49         69      0.701      0.475       0.57      0.436\n",
            "           sports ball        169        260      0.763      0.606       0.64      0.467\n",
            "                  kite         91        327      0.665      0.571      0.626       0.44\n",
            "          baseball bat         97        145      0.721      0.545      0.595      0.373\n",
            "        baseball glove        100        148      0.795      0.575      0.651      0.392\n",
            "            skateboard        127        179       0.82      0.771      0.792      0.595\n",
            "             surfboard        149        267      0.766      0.581       0.64       0.42\n",
            "         tennis racket        167        225      0.775      0.729      0.799      0.534\n",
            "                bottle        379       1013      0.677      0.507      0.576      0.394\n",
            "            wine glass        110        341      0.767      0.472       0.58      0.388\n",
            "                   cup        390        895      0.651      0.534      0.605      0.452\n",
            "                  fork        155        215      0.654       0.47      0.563      0.405\n",
            "                 knife        181        325      0.569      0.262      0.326      0.205\n",
            "                 spoon        153        253      0.521      0.285      0.315      0.212\n",
            "                  bowl        314        623      0.662      0.559      0.605      0.452\n",
            "                banana        103        370      0.548      0.324      0.423      0.277\n",
            "                 apple         76        236      0.513       0.33       0.32      0.222\n",
            "              sandwich         98        177      0.579       0.52      0.555      0.423\n",
            "                orange         85        285      0.491        0.4      0.419      0.325\n",
            "              broccoli         71        312      0.552      0.385        0.4      0.239\n",
            "                carrot         81        365      0.492      0.351      0.369      0.238\n",
            "               hot dog         51        125      0.652      0.472      0.541      0.414\n",
            "                 pizza        153        284      0.757      0.683      0.745      0.571\n",
            "                 donut         62        328      0.654       0.57      0.617      0.488\n",
            "                  cake        124        310      0.682      0.555      0.626      0.432\n",
            "                 chair        580       1771      0.662       0.44       0.52      0.345\n",
            "                 couch        195        261      0.648      0.617      0.671      0.532\n",
            "          potted plant        172        342      0.573      0.442      0.492      0.307\n",
            "                   bed        149        163      0.668       0.62      0.693      0.503\n",
            "          dining table        501        695      0.586      0.469      0.501      0.355\n",
            "                toilet        149        179      0.785      0.835      0.851       0.71\n",
            "                    tv        207        288       0.81      0.712      0.816      0.631\n",
            "                laptop        183        231      0.769      0.736      0.796      0.667\n",
            "                 mouse         88        106       0.79      0.745      0.792      0.617\n",
            "                remote        145        283       0.65      0.393      0.496       0.32\n",
            "              keyboard        106        153      0.708      0.614      0.722      0.549\n",
            "            cell phone        214        262      0.692      0.504      0.569      0.378\n",
            "             microwave         54         55      0.723      0.709      0.784      0.637\n",
            "                  oven        115        143      0.657      0.563      0.621      0.448\n",
            "               toaster          8          9      0.661      0.778      0.785      0.574\n",
            "                  sink        187        225      0.695      0.564      0.623      0.429\n",
            "          refrigerator        101        126      0.796      0.738      0.799      0.679\n",
            "                  book        230       1129      0.541      0.151      0.251      0.135\n",
            "                 clock        204        267      0.784      0.697      0.748      0.536\n",
            "                  vase        137        274      0.671      0.588      0.588      0.423\n",
            "              scissors         28         36      0.759      0.444      0.477      0.378\n",
            "            teddy bear         94        190      0.733      0.668      0.718       0.55\n",
            "            hair drier          9         11      0.361     0.0657     0.0828     0.0438\n",
            "            toothbrush         34         57      0.602      0.404      0.457      0.329\n",
            "Speed: 3.7ms preprocess, 529.4ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Saving runs/detect/val3/predictions.json...\n",
            "\n",
            "Evaluating pycocotools mAP using runs/detect/val3/predictions.json and /content/datasets/coco/annotations/instances_val2017.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.87s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=5.51s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=56.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=8.16s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.506\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.361\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt'...\n",
            "100% 38.8M/38.8M [00:00<00:00, 185MB/s]\n",
            "Ultralytics 8.3.72 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "YOLO11m summary (fused): 303 layers, 20,091,712 parameters, 0 gradients, 68.0 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/labels/val2017.cache... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  81% 252/313 [1:36:06<24:56, 24.53s/it]"
          ]
        }
      ]
    }
  ]
}